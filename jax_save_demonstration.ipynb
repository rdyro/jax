{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A proposal for defining `jax.save` and `jax.load`\n",
    "... or perhaps something like `jax.save_to_dir` and `jax.load_from_dir`\n",
    "\n",
    "### Objectives for the new API:\n",
    "\n",
    "The new API should be:\n",
    "- simple\n",
    "- strict by default (no pickle), but allow pickle\n",
    "    - but allow storing in-built values like numbers (e.g., int, float), strings and bytes\n",
    "- not be pickle, should be significantly orthogonal to what pickle does\n",
    "    - NOTE: the effort to support some pickling JAX arrays is also important\n",
    "- provide the ability for partial reads\n",
    "- allow to read and write arrays in a distributed sharded context\n",
    "    - this is already supported with tensorstore (and Yash's low-level API)\n",
    "- have an `async` version for both save and load\n",
    "- have the ability to read in just the structure of the data\n",
    "- have a flat storage of leaf data that the user can access themselves\n",
    "- support remote reading and writing from/to cloud storage, GCS and S3 at a minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from subprocess import check_output\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass\n",
    "import functools\n",
    "from typing import Any\n",
    "import pickle\n",
    "\n",
    "import jax\n",
    "from jax.experimental.array_serialization.new_api import save, load, load_pytree\n",
    "from jax import numpy as jnp, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"hello\", {\"world\": [\"!\", (1, 2)]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = tempfile.TemporaryDirectory().name\n",
    "save(data, tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `pytreedef.json` is a human-readable pytree stored format\n",
      "{\n",
      "  \"__jax_tree_repr\": {\n",
      "    \"node_type\": \"builtins.list\",\n",
      "    \"node_data_ref\": null,\n",
      "    \"children\": [\n",
      "      {\n",
      "        \"node_type\": \"leaf\",\n",
      "        \"node_data_ref\": null,\n",
      "        \"children\": [],\n",
      "        \"leaf_id\": \"str -> e4b2fd01-19b1-4a93-ada8-e07efaeb4867\"\n",
      "      },\n",
      "      {\n",
      "        \"node_type\": \"builtins.dict\",\n",
      "        \"node_data_ref\": [\n",
      "          \"world\"\n",
      "        ],\n",
      "        \"children\": [\n",
      "          {\n",
      "            \"node_type\": \"builtins.list\",\n",
      "            \"node_data_ref\": null,\n",
      "            \"children\": [\n",
      "              {\n",
      "                \"node_type\": \"leaf\",\n",
      "                \"node_data_ref\": null,\n",
      "                \"children\": [],\n",
      "                \"leaf_id\": \"str -> 575bfa86-ed48-47f5-bac8-a799afc17809\"\n",
      "              },\n",
      "              {\n",
      "                \"node_type\": \"builtins.tuple\",\n",
      "                \"node_data_ref\": null,\n",
      "                \"children\": [\n",
      "                  {\n",
      "                    \"node_type\": \"leaf\",\n",
      "                    \"node_data_ref\": null,\n",
      "                    \"children\": [],\n",
      "                    \"leaf_id\": \"int -> 29e85017-058f-4bcc-9464-f5baa9d1924d\"\n",
      "                  },\n",
      "                  {\n",
      "                    \"node_type\": \"leaf\",\n",
      "                    \"node_data_ref\": null,\n",
      "                    \"children\": [],\n",
      "                    \"leaf_id\": \"int -> 60706ed3-be9e-42dd-aff1-5d630e42ef1a\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"__jax_leaf_ids\": [\n",
      "    \"str -> e4b2fd01-19b1-4a93-ada8-e07efaeb4867\",\n",
      "    \"str -> 575bfa86-ed48-47f5-bac8-a799afc17809\",\n",
      "    \"int -> 29e85017-058f-4bcc-9464-f5baa9d1924d\",\n",
      "    \"int -> 60706ed3-be9e-42dd-aff1-5d630e42ef1a\"\n",
      "  ]\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "The leaf data is organized in a flat directory under `leaf_data`\n",
      "\u001b[01;34m/tmp/tmpe6rar0vo\u001b[0m\n",
      "├── \u001b[01;34mleaf_data\u001b[0m\n",
      "│   ├── \u001b[00m29e85017-058f-4bcc-9464-f5baa9d1924d.json\u001b[0m\n",
      "│   ├── \u001b[00m575bfa86-ed48-47f5-bac8-a799afc17809.json\u001b[0m\n",
      "│   ├── \u001b[00m60706ed3-be9e-42dd-aff1-5d630e42ef1a.json\u001b[0m\n",
      "│   └── \u001b[00me4b2fd01-19b1-4a93-ada8-e07efaeb4867.json\u001b[0m\n",
      "└── \u001b[00mpytreedef.json\u001b[0m\n",
      "\n",
      "2 directories, 5 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The `pytreedef.json` is a human-readable pytree stored format\")\n",
    "print((Path(tmpdir) / \"pytreedef.json\").read_text())\n",
    "print(\"-\" * 80)\n",
    "print(\"The leaf data is organized in a flat directory under `leaf_data`\")\n",
    "print(check_output([\"tree\", tmpdir]).decode()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "PyTree Structure:\n",
      "['str -> e4b2fd01-19b1-4a93-ada8-e07efaeb4867',\n",
      " {'world': ['str -> 575bfa86-ed48-47f5-bac8-a799afc17809',\n",
      "            ('int -> 29e85017-058f-4bcc-9464-f5baa9d1924d',\n",
      "             'int -> 60706ed3-be9e-42dd-aff1-5d630e42ef1a')]}]\n"
     ]
    }
   ],
   "source": [
    "# read only the data structure\n",
    "print(\"-\" * 80)\n",
    "print(\"PyTree Structure:\")\n",
    "pytree_structure = load_pytree(tmpdir)\n",
    "pprint(pytree_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Partial read of data:\n",
      "[None, {'world': [None, (1, 2)]}]\n"
     ]
    }
   ],
   "source": [
    "# read only integers back\n",
    "print(\"-\" * 80)\n",
    "print(\"Partial read of data:\")\n",
    "pytree_structure = jax.tree.map(lambda x: None if x.startswith(\"str\") else x, pytree_structure)\n",
    "new_data = load(tmpdir, pytree=pytree_structure)\n",
    "pprint(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allowing custom nodes with `pickle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly refusing to serialize custom objects\n",
      "Serialized with pickle\n",
      "Extra folder: `node_data`\n",
      "\u001b[01;34m/tmp/tmpi3o49fav\u001b[0m\n",
      "├── \u001b[01;34mleaf_data\u001b[0m\n",
      "│   ├── \u001b[00m2b2a436a-afca-4fbf-a5cd-6a81c3b53c69.json\u001b[0m\n",
      "│   ├── \u001b[01;34m8c1c43cf-5d57-493b-877e-aa396afef9d1.tensorstore\u001b[0m\n",
      "│   └── \u001b[00mce4aec25-642a-41d8-9557-cce14798da21.json\u001b[0m\n",
      "├── \u001b[01;34mnode_data\u001b[0m\n",
      "│   └── \u001b[00mef09d15c-5698-4b13-b8e4-19fc97fb7dbf.pickle\u001b[0m\n",
      "└── \u001b[00mpytreedef.json\u001b[0m\n",
      "\n",
      "4 directories, 4 files\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{\n",
      "  \"__jax_tree_repr\": {\n",
      "    \"node_type\": \"builtins.dict\",\n",
      "    \"node_data_ref\": [\n",
      "      \"a\",\n",
      "      \"dataclass\"\n",
      "    ],\n",
      "    \"children\": [\n",
      "      {\n",
      "        \"node_type\": \"leaf\",\n",
      "        \"node_data_ref\": null,\n",
      "        \"children\": [],\n",
      "        \"leaf_id\": \"int -> 2b2a436a-afca-4fbf-a5cd-6a81c3b53c69\"\n",
      "      },\n",
      "      {\n",
      "        \"node_type\": \"__main__.D\",\n",
      "        \"node_data_ref\": \"ef09d15c-5698-4b13-b8e4-19fc97fb7dbf\",\n",
      "        \"children\": [\n",
      "          {\n",
      "            \"node_type\": \"leaf\",\n",
      "            \"node_data_ref\": null,\n",
      "            \"children\": [],\n",
      "            \"leaf_id\": \"float32[7] -> 8c1c43cf-5d57-493b-877e-aa396afef9d1\"\n",
      "          },\n",
      "          {\n",
      "            \"node_type\": \"leaf\",\n",
      "            \"node_data_ref\": null,\n",
      "            \"children\": [],\n",
      "            \"leaf_id\": \"int -> ce4aec25-642a-41d8-9557-cce14798da21\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"__jax_leaf_ids\": [\n",
      "    \"int -> 2b2a436a-afca-4fbf-a5cd-6a81c3b53c69\",\n",
      "    \"float32[7] -> 8c1c43cf-5d57-493b-877e-aa396afef9d1\",\n",
      "    \"int -> ce4aec25-642a-41d8-9557-cce14798da21\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@functools.partial(jax.tree_util.register_dataclass, data_fields=[\"a\", \"c\"], \n",
    "                   meta_fields=[\"op\"])\n",
    "@dataclass\n",
    "class D:\n",
    "  op: str\n",
    "  a: Any\n",
    "  c: int\n",
    "  \n",
    "tmpdir = tempfile.TemporaryDirectory().name\n",
    "try:\n",
    "  save({\"dataclass\": D(\"tanh\", random.normal(random.key(0), (7,)), 5), \n",
    "        \"a\": 1}, tmpdir)\n",
    "except ValueError:\n",
    "  print(\"Correctly refusing to serialize custom objects\")\n",
    "\n",
    "save({\"dataclass\": D(\"tanh\", random.normal(random.key(0), (7,)), 5), \n",
    "      \"a\": 1}, tmpdir, pickle_module=pickle)\n",
    "print(\"Serialized with pickle\")\n",
    "\n",
    "print(\"Extra folder: `node_data`\")\n",
    "print(check_output([\"tree\", \"-L\", \"2\", tmpdir]).decode()) \n",
    "print(\"-\" * 80)\n",
    "print((Path(tmpdir) / \"pytreedef.json\").read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly refuses to read without pickle\n",
      "Reads corectly with pickle\n",
      "{'a': 1, 'dataclass': D(op='tanh', a=Array([ 0.08086783, -0.38624713, -0.37565565,  0.58691907, -1.2758198 ,\n",
      "        2.1192005 , -0.85821223], dtype=float32), c=5)}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  load(tmpdir)\n",
    "except ValueError:\n",
    "  print(\"Correctly refuses to read without pickle\")\n",
    "\n",
    "print(\"Reads corectly with pickle\")\n",
    "print(load(tmpdir, pickle_module=pickle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best-effort reading when pickled objects are no longer available\n",
    "\n",
    "We can also attempt to load with `best_effort=True` without pickle or if the class definition / custom node registration has been lost.\n",
    "\n",
    "This will print a warning and will read the children of the former custom node and organized them in a list.\n",
    "\n",
    "All node data (e.g., static fields) are not read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unrecognized data type `__main__.D` we'll do our best and just return a list of children\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'dataclass': [Array([ 0.08086783, -0.38624713, -0.37565565,  0.58691907, -1.2758198 ,\n",
      "        2.1192005 , -0.85821223], dtype=float32), 5]}\n"
     ]
    }
   ],
   "source": [
    "print(load(tmpdir, best_effort=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. Must the resulting checkpoint be a directory? Can it not be a file?\n",
    "\n",
    "> The underlying checkpoint is a directory, tensorstore doesn't really support\n",
    "> writing single-file checkpoints that are well read-optimized.\n",
    "\n",
    "> It's possible to zip the result, piece-by-piece without wasting disk space,\n",
    "> which is probably a direction to explore. NOTE: tensorstore seems to support\n",
    "> **reading** from Python zipfile handles directly.\n",
    "\n",
    "2. How CPU efficient is saving the checkpoint?\n",
    "\n",
    "> Thanks to the underlying async usage, it should be pretty efficient.\n",
    "\n",
    "3. Is RAM usage controlled?\n",
    "\n",
    "> Not at the moment, but it's possible to improve this. We can use tensorstore\n",
    "> to limit array writing memory usage and we can rewrite non-array writing to be\n",
    "> non-buffered through a bytes or text object (they are buffered to more cleanly\n",
    "> support file://, gcs://, s3:// alternatives).\n",
    "\n",
    "4. Why is the `pytreedef.json` weird like that?\n",
    "\n",
    "> The \"cleanest\" way to save a pytree structure is to just use a JSON\n",
    "> representation with leafs replaced with their data reference id. However,\n",
    "> JSON doesn't distinguish between tuple, list and so it doesn't really preserve\n",
    "> the actual pytree, even if it's limited to only in-built types. Also, when the\n",
    "> pytree contains custom nodes, we need a custom tree representation anyway.\n",
    "\n",
    "5. Isn't overwriting a **directory** checkpoint extremely dangerous if the \n",
    "\"checkpoint\" path turns out to be e.g \"/usr/local\"?\n",
    "\n",
    "> Yes, but we first check for files and directories we didn't create and refuse\n",
    "> to overwrite if there are any.\n",
    "\n",
    "6. Why doesn't Python LSP not work with synchronous versions: `save`, `load`?\n",
    "\n",
    "> I don't know, I need to fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
