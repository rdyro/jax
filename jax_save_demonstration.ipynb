{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A proposal for defining `jax.save` and `jax.load`\n",
    "... or perhaps something like `jax.save_to_dir` and `jax.load_from_dir`\n",
    "\n",
    "### Objectives for the new API:\n",
    "\n",
    "The new API should be:\n",
    "- simple\n",
    "- strict by default (no pickle), but allow pickle\n",
    "    - but allow storing in-built values like numbers (e.g., int, float), strings and bytes\n",
    "- not be pickle, should be significantly orthogonal to what pickle does\n",
    "    - NOTE: the effort to support some pickling JAX arrays is also important\n",
    "- provide the ability for partial reads\n",
    "- allow to read and write arrays in a distributed sharded context\n",
    "    - this is already supported with tensorstore (and Yash's low-level API)\n",
    "- have an `async` version for both save and load\n",
    "- have the ability to read in just the structure of the data\n",
    "- have a flat storage of leaf data that the user can access themselves\n",
    "- support remote reading and writing from/to cloud storage, GCS and S3 at a minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from subprocess import check_output\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "import jax\n",
    "from jax.experimental.array_serialization.new_api import save, load, load_pytree\n",
    "from jax.experimental.array_serialization.new_api import async_save, async_load\n",
    "from jax import numpy as jnp, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"hello\", {\"world\": [\"!\", (1, 2)]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = tempfile.TemporaryDirectory().name\n",
    "fut = save(data, tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `pytreedef.json` is a human-readable pytree stored format\n",
      "{\n",
      "  \"__jax_tree_repr\": {\n",
      "    \"node_type\": \"builtins.list\",\n",
      "    \"node_data_ref\": null,\n",
      "    \"children\": [\n",
      "      {\n",
      "        \"node_type\": \"leaf\",\n",
      "        \"node_data_ref\": null,\n",
      "        \"children\": [],\n",
      "        \"leaf_id\": \"str -> 11adcd12-df14-4407-9c73-7c1e81554225\"\n",
      "      },\n",
      "      {\n",
      "        \"node_type\": \"builtins.dict\",\n",
      "        \"node_data_ref\": [\n",
      "          \"world\"\n",
      "        ],\n",
      "        \"children\": [\n",
      "          {\n",
      "            \"node_type\": \"builtins.list\",\n",
      "            \"node_data_ref\": null,\n",
      "            \"children\": [\n",
      "              {\n",
      "                \"node_type\": \"leaf\",\n",
      "                \"node_data_ref\": null,\n",
      "                \"children\": [],\n",
      "                \"leaf_id\": \"str -> af93447e-5b7f-4a90-b6b8-c2d3f6a99cc3\"\n",
      "              },\n",
      "              {\n",
      "                \"node_type\": \"builtins.tuple\",\n",
      "                \"node_data_ref\": null,\n",
      "                \"children\": [\n",
      "                  {\n",
      "                    \"node_type\": \"leaf\",\n",
      "                    \"node_data_ref\": null,\n",
      "                    \"children\": [],\n",
      "                    \"leaf_id\": \"int -> 4b1ab321-1c93-40d8-9e50-bea286c4e965\"\n",
      "                  },\n",
      "                  {\n",
      "                    \"node_type\": \"leaf\",\n",
      "                    \"node_data_ref\": null,\n",
      "                    \"children\": [],\n",
      "                    \"leaf_id\": \"int -> f5ffe274-368a-448b-aa4f-4db8f8d5353e\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"__jax_leaf_ids\": [\n",
      "    \"str -> 11adcd12-df14-4407-9c73-7c1e81554225\",\n",
      "    \"str -> af93447e-5b7f-4a90-b6b8-c2d3f6a99cc3\",\n",
      "    \"int -> 4b1ab321-1c93-40d8-9e50-bea286c4e965\",\n",
      "    \"int -> f5ffe274-368a-448b-aa4f-4db8f8d5353e\"\n",
      "  ]\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "The leaf data is organized in a flat directory under `leaf_data`\n",
      "\u001b[01;34m/tmp/tmpprlpngyj\u001b[0m\n",
      "├── \u001b[01;34mleaf_data\u001b[0m\n",
      "│   ├── \u001b[00m11adcd12-df14-4407-9c73-7c1e81554225.json\u001b[0m\n",
      "│   ├── \u001b[00m4b1ab321-1c93-40d8-9e50-bea286c4e965.json\u001b[0m\n",
      "│   ├── \u001b[00maf93447e-5b7f-4a90-b6b8-c2d3f6a99cc3.json\u001b[0m\n",
      "│   └── \u001b[00mf5ffe274-368a-448b-aa4f-4db8f8d5353e.json\u001b[0m\n",
      "└── \u001b[00mpytreedef.json\u001b[0m\n",
      "\n",
      "2 directories, 5 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The `pytreedef.json` is a human-readable pytree stored format\")\n",
    "print((Path(tmpdir) / \"pytreedef.json\").read_text())\n",
    "print(\"-\" * 80)\n",
    "print(\"The leaf data is organized in a flat directory under `leaf_data`\")\n",
    "print(check_output([\"tree\", tmpdir]).decode()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "PyTree Structure:\n",
      "['str -> ae6f15cf-9a75-4a4f-8b5c-2a1e127ea876',\n",
      " {'world': ['str -> 9b4dcc9a-79b6-4be5-83a3-37e98589d12c',\n",
      "            ('int -> 8d4f45e7-d2ad-42ee-a1c6-9a91132f844e',\n",
      "             'int -> d220f546-d89e-411e-a964-91019ff2a7e1')]}]\n"
     ]
    }
   ],
   "source": [
    "# read only the data structure\n",
    "print(\"-\" * 80)\n",
    "print(\"PyTree Structure:\")\n",
    "pytree_structure = load_pytree(tmpdir)\n",
    "pprint(pytree_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Partial read of data:\n",
      "[None, {'world': [None, (1, 2)]}]\n"
     ]
    }
   ],
   "source": [
    "# read only integers back\n",
    "print(\"-\" * 80)\n",
    "print(\"Partial read of data:\")\n",
    "pytree_structure = jax.tree.map(lambda x: None if x.startswith(\"str\") else x, pytree_structure)\n",
    "new_data = load(tmpdir, pytree=pytree_structure)\n",
    "pprint(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allowing custom nodes with `pickle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly refusing to serialize custom objects\n",
      "Serialized with pickle\n",
      "Extra folder: `node_data`\n",
      "\u001b[01;34m/tmp/tmpq0ynbpgj\u001b[0m\n",
      "├── \u001b[01;34mleaf_data\u001b[0m\n",
      "│   ├── \u001b[01;34m03b4d39f-461c-4ada-9f4a-e8023dfccc8a.tensorstore\u001b[0m\n",
      "│   ├── \u001b[00m19198e06-1c22-4753-a7db-9a3b5a395d2c.json\u001b[0m\n",
      "│   └── \u001b[00m6cd99248-f4b6-4c8c-89a8-1343b119fdc5.json\u001b[0m\n",
      "├── \u001b[01;34mnode_data\u001b[0m\n",
      "│   └── \u001b[00mabebfdb4-5663-442b-8fb5-4b15469e33eb.pickle\u001b[0m\n",
      "└── \u001b[00mpytreedef.json\u001b[0m\n",
      "\n",
      "4 directories, 4 files\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{\n",
      "  \"__jax_tree_repr\": {\n",
      "    \"node_type\": \"builtins.dict\",\n",
      "    \"node_data_ref\": [\n",
      "      \"a\",\n",
      "      \"dataclass\"\n",
      "    ],\n",
      "    \"children\": [\n",
      "      {\n",
      "        \"node_type\": \"leaf\",\n",
      "        \"node_data_ref\": null,\n",
      "        \"children\": [],\n",
      "        \"leaf_id\": \"int -> 6cd99248-f4b6-4c8c-89a8-1343b119fdc5\"\n",
      "      },\n",
      "      {\n",
      "        \"node_type\": \"__main__.D\",\n",
      "        \"node_data_ref\": \"abebfdb4-5663-442b-8fb5-4b15469e33eb\",\n",
      "        \"children\": [\n",
      "          {\n",
      "            \"node_type\": \"leaf\",\n",
      "            \"node_data_ref\": null,\n",
      "            \"children\": [],\n",
      "            \"leaf_id\": \"float32[7] -> 03b4d39f-461c-4ada-9f4a-e8023dfccc8a\"\n",
      "          },\n",
      "          {\n",
      "            \"node_type\": \"leaf\",\n",
      "            \"node_data_ref\": null,\n",
      "            \"children\": [],\n",
      "            \"leaf_id\": \"int -> 19198e06-1c22-4753-a7db-9a3b5a395d2c\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"__jax_leaf_ids\": [\n",
      "    \"int -> 6cd99248-f4b6-4c8c-89a8-1343b119fdc5\",\n",
      "    \"float32[7] -> 03b4d39f-461c-4ada-9f4a-e8023dfccc8a\",\n",
      "    \"int -> 19198e06-1c22-4753-a7db-9a3b5a395d2c\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#@functools.partial(jax.tree_util.register_dataclass, data_fields=[\"a\", \"c\"], \n",
    "#                   meta_fields=[\"op\"])\n",
    "@jax.tree_util.register_pytree_node_class\n",
    "@dataclass\n",
    "class D:\n",
    "  op: str\n",
    "  a: Any\n",
    "  c: int\n",
    "\n",
    "  def tree_flatten(self):\n",
    "    return ((self.a, self.c), self.op)\n",
    "\n",
    "  @classmethod\n",
    "  def tree_unflatten(cls, aux_data, children):\n",
    "    return cls(aux_data, *children)\n",
    "  \n",
    "tmpdir = tempfile.TemporaryDirectory().name\n",
    "try:\n",
    "  save({\"dataclass\": D(\"tanh\", random.normal(random.key(0), (7,)), 5), \n",
    "        \"a\": 1}, tmpdir)\n",
    "except ValueError:\n",
    "  print(\"Correctly refusing to serialize custom objects\")\n",
    "\n",
    "save({\"dataclass\": D(\"tanh\", random.normal(random.key(0), (7,)), 5), \n",
    "      \"a\": 1}, tmpdir, pickle_module=pickle)\n",
    "print(\"Serialized with pickle\")\n",
    "\n",
    "print(\"Extra folder: `node_data`\")\n",
    "print(check_output([\"tree\", \"-L\", \"2\", tmpdir]).decode()) \n",
    "print(\"-\" * 80)\n",
    "print((Path(tmpdir) / \"pytreedef.json\").read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly refuses to read without pickle\n",
      "Reads corectly with pickle\n",
      "{'a': 1, 'dataclass': D(op='tanh', a=Array([ 0.08086783, -0.38624713, -0.37565565,  0.58691907, -1.2758198 ,\n",
      "        2.1192005 , -0.85821223], dtype=float32), c=5)}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  load(tmpdir)\n",
    "except ValueError:\n",
    "  print(\"Correctly refuses to read without pickle\")\n",
    "\n",
    "print(\"Reads corectly with pickle\")\n",
    "print(load(tmpdir, pickle_module=pickle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best-effort reading when pickled objects are no longer available\n",
    "\n",
    "We can also attempt to load with `best_effort=True` without pickle or if the class definition / custom node registration has been lost.\n",
    "\n",
    "This will print a warning and will read the children of the former custom node and organized them in a list.\n",
    "\n",
    "All node data (e.g., static fields) are not read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unrecognized data type `__main__.D` we'll do our best and just return a list of children\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'dataclass': [Array([ 0.08086783, -0.38624713, -0.37565565,  0.58691907, -1.2758198 ,\n",
      "        2.1192005 , -0.85821223], dtype=float32), 5]}\n"
     ]
    }
   ],
   "source": [
    "print(load(tmpdir, best_effort=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unrecognized data type `__main__.D` we'll do our best and just return a list of children\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 'int -> 6cd99248-f4b6-4c8c-89a8-1343b119fdc5',\n",
       " 'dataclass': ['float32[7] -> 03b4d39f-461c-4ada-9f4a-e8023dfccc8a',\n",
       "  'int -> 19198e06-1c22-4753-a7db-9a3b5a395d2c']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pytree(tmpdir, best_effort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful! PyTree utils do not preserve key order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 1, 'a': 2}\n",
      "{'a': 2, 'c': 1}\n"
     ]
    }
   ],
   "source": [
    "d = {\"c\": 1, \"a\": 2}\n",
    "d2 = jax.tree.unflatten(jax.tree.structure(d), jax.tree.flatten(d)[0])\n",
    "print(d)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `OrderedDict` is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('c', 1), ('a', 2)])\n",
      "OrderedDict([('c', 1), ('a', 2)])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict as odict\n",
    "d = odict({\"c\": 1, \"a\": 2})\n",
    "d2 = jax.tree.unflatten(jax.tree.structure(d), jax.tree.flatten(d)[0])\n",
    "print(d)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "async_save() missing 1 required keyword-only argument: 'sync'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fut \u001b[38;5;241m=\u001b[39m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43modict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_checkpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: async_save() missing 1 required keyword-only argument: 'sync'"
     ]
    }
   ],
   "source": [
    "fut = save(odict({\"c\": jnp.ones(100), \"a\": 2}), \"test_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fut.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fut.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('c',\n",
       "              Array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                     1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                     1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                     1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                     1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                     1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],      dtype=float32)),\n",
       "             ('a', 2)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load(\"test_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended safe-modules\n",
    "\n",
    "We probably want to be able to support non-JAX, but very standard collections\n",
    "like e.g., flax's `FrozenDict` (and I can't think of anything else).\n",
    "\n",
    "To do this programmatically, we can add **string** entries to \n",
    "`new_api._EXTENDED_NODE_TYPES_MAP` which we then use `importlib` on on the fly.\n",
    "\n",
    "The alternative is to allow this importlib on-the-fly import for all modules\n",
    "that are:\n",
    "1. not a member of `__main__` module \n",
    "2. do not contain any non-JSON serializable `node_data()`\n",
    "\n",
    "But this would mean calling `importlib.import_module` on a data string, so it's\n",
    "pretty unsafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "  save(collections.OrderedDict(a=1, b=jnp.ones(10)), tmpdir)\n",
    "  restored_tree = load(tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  from flax.core.frozen_dict import FrozenDict\n",
    "  # FrozenDict is added to the list at the moment\n",
    "  with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    save(FrozenDict(a=1, b=jnp.ones(10)), tmpdir)\n",
    "    restored_tree = load(tmpdir)\n",
    "except ImportError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. Must the resulting checkpoint be a directory? Can it not be a file?\n",
    "\n",
    "> The underlying checkpoint is a directory, tensorstore doesn't really support\n",
    "> writing single-file checkpoints that are well read-optimized.\n",
    "\n",
    "> It's possible to zip the result, piece-by-piece without wasting disk space,\n",
    "> which is probably a direction to explore. NOTE: tensorstore seems to support\n",
    "> **reading** from Python zipfile handles directly.\n",
    "\n",
    "2. How fast is saving the checkpoint given I/O can be slow?\n",
    "\n",
    "> Thanks to the underlying async usage, it should be pretty fast.\n",
    "\n",
    "3. Is RAM usage controlled?\n",
    "\n",
    "> Not at the moment, but it's possible to improve this. We can use tensorstore\n",
    "> to limit array writing memory usage and we can rewrite non-array writing to be\n",
    "> non-buffered through a bytes or text object (they are buffered to more cleanly\n",
    "> support file://, gcs://, s3:// alternatives).\n",
    "\n",
    "4. Why is the `pytreedef.json` weird like that?\n",
    "\n",
    "> The \"cleanest\" way to save a pytree structure is to just use a JSON\n",
    "> representation with leafs replaced with their data reference id. However,\n",
    "> JSON doesn't distinguish between tuple, list and so it doesn't really preserve\n",
    "> the actual pytree, even if it's limited to only in-built types. Also, when the\n",
    "> pytree contains custom nodes, we need a custom tree representation anyway.\n",
    "\n",
    "5. Isn't overwriting a **directory** checkpoint extremely dangerous if the \n",
    "\"checkpoint\" path turns out to be e.g \"/usr/local\"?\n",
    "\n",
    "> Yes, but we first check for files and directories we didn't create and refuse\n",
    "> to overwrite if there are any.\n",
    "\n",
    "6. Why doesn't Python LSP not work with synchronous versions: `save`, `load`?\n",
    "\n",
    "I don't know, I need to fix it.\n",
    "\n",
    "7. Restored pytrees have dictionary node keys in a different order. Why?\n",
    "\n",
    "> This is pytree behavior, dictionaries order is not preserved.\n",
    "> [https://github.com/google/jax/issues/4085](https://github.com/google/jax/issues/4085)\n",
    "\n",
    "8. Which host (process_id) writes the save directory and what part of it?\n",
    "\n",
    "> Currently if remote path is detected, only `jax.process_idx() == 0` writes \n",
    "> non-arrays. All processes write arrays as that is what tensorstore expects.\n",
    "\n",
    "9. TODO\n",
    "\n",
    "> - passing sharding not tested"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
