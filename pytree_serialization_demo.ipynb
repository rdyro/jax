{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A proposal for defining `jax.tree.save` and `jax.tree.load`\n",
    "... or perhaps something like `jax.tree.save_to_dir` and `jax.tree.load_from_dir`\n",
    "\n",
    "### Objectives for the new API:\n",
    "\n",
    "The new API should be:\n",
    "- simple\n",
    "- strict by default (no pickle), but allow pickle\n",
    "    - but allow storing in-built values like numbers (e.g., int, float), strings and bytes\n",
    "- not be pickle, should be significantly orthogonal to what pickle does\n",
    "- partial reads and writes\n",
    "- distributed sharded context\n",
    "    - already supported with tensorstore (and Yash's low-level API)\n",
    "- nonblocking version for both save and load\n",
    "- read just the structure of the data\n",
    "- support remote reading and writing from/to cloud storage, GCS and S3 at a minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from subprocess import check_output\n",
    "from pprint import pprint\n",
    "import functools\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "import pickle\n",
    "import collections\n",
    "from types import SimpleNamespace\n",
    "\n",
    "os.environ[\"JAX_ENABLE_X64\"] = \"1\"\n",
    "\n",
    "import jax\n",
    "from jax.experimental.array_serialization.pytree_serialization import (\n",
    "  save, load, load_pytreedef, nonblocking_save, nonblocking_load)\n",
    "from jax.experimental.array_serialization.pytree_serialization_utils import (\n",
    "  register_pytree_node_serialization, \n",
    "  #register_pytree_leaf_serialization\n",
    ")\n",
    "from jax.experimental.array_serialization import pytree_serialization_utils as utils\n",
    "from jax import numpy as jnp, random\n",
    "from jax import tree\n",
    "import numpy as np\n",
    "\n",
    "tree.save = save\n",
    "tree.load = load\n",
    "tree.load_pytreedef = load_pytreedef\n",
    "tree.nonblocking_load = nonblocking_load\n",
    "tree.nonblocking_save = nonblocking_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register a custom node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_dumps(aux_data):\n",
    "  print(f\"hello from json_dumps: {aux_data}\")\n",
    "  return json.dumps(aux_data).encode(\"utf-8\")\n",
    "\n",
    "def json_loads(aux_data):\n",
    "  return json.loads(aux_data)\n",
    "\n",
    "@functools.partial(register_pytree_node_serialization, \n",
    "                   serialized_name=\"class_D\",\n",
    "                   serialize_auxdata=json_dumps, \n",
    "                   deserialize_auxdata=json_loads)\n",
    "@functools.partial(jax.tree_util.register_dataclass, data_fields=[\"a\", \"b\"], \n",
    "                   meta_fields=[])\n",
    "@dataclass\n",
    "class D:\n",
    "  a: int\n",
    "  b: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loads(x):\n",
    "  return json.loads(x)\n",
    "\n",
    "dumps = lambda x: json.dumps(x).encode(\"utf-8\")\n",
    "print(f\"loads hash = {hash(loads)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "save(bytearray(b\"hello\"), tempdir)\n",
    "out = load(tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "print(tempdir)\n",
    "save(D(1, 2), tempdir)\n",
    "load_pytreedef(tempdir)\n",
    "load(tempdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple use-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapedArray(float64[10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.typeof(jnp.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpd_q_p7_z\n",
      "CPU times: user 42.8 ms, sys: 40.4 ms, total: 83.1 ms\n",
      "Wall time: 94.3 ms\n",
      "CPU times: user 13.2 ms, sys: 12.3 ms, total: 25.5 ms\n",
      "Wall time: 19.6 ms\n",
      "[Array(1, dtype=int64), {'world': [Array([[[1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.]],\n",
      "\n",
      "       [[1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float64), (Array([0., 0., 0.], dtype=float64), Array([1., 1., 1., 1.], dtype=float64))]}, Array([1., 1., 1., 1., 1.], dtype=float64)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Array(True, dtype=bool),\n",
       " {'world': [Array(True, dtype=bool),\n",
       "   (Array(True, dtype=bool), Array(True, dtype=bool))]},\n",
       " Array(True, dtype=bool)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = [\"hello\", {\"world\": [\"!\", (1, 2)]}, None, jnp.ones(5)]\n",
    "data = [jnp.array(1), {\"world\": [jnp.ones((2, 1024, 1024)), (jnp.zeros(3), jnp.ones(4))]}, jnp.ones(5)]\n",
    "\n",
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "print(tempdir)\n",
    "%time fut = tree.save(data, tempdir)\n",
    "%time restored_data = tree.load(tempdir)\n",
    "print(restored_data)\n",
    "\n",
    "jax.tree.map(lambda x, y: jnp.all(x == y), data, restored_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ShapeDtypeStruct(shape=(), dtype=int64),\n",
       " {'world': [ShapeDtypeStruct(shape=(2, 1024, 1024), dtype=float64),\n",
       "   (ShapeDtypeStruct(shape=(3,), dtype=float64),\n",
       "    ShapeDtypeStruct(shape=(4,), dtype=float64))]},\n",
       " ShapeDtypeStruct(shape=(5,), dtype=float64)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.load_pytreedef(tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `pytreedef.json` is a human-readable pytree stored format\n",
      "{\n",
      "  \"__jax_pytreedef_repr\": \"BAAAAJD///8IAAAAAAAAAwMAAACQAAAAGAAAAAQAAACA////AAAKABAADwAIAAQACgAAAAwAAAAcAAAAAAAABAEAAAAEAAAABQAAAHdvcmxkAAAAAQAAAAQAAADo////CAAAAAAAAAMCAAAAMAAAAAwAAAAIAAwACwAEAAgAAAAIAAAAAAAAAgIAAAAMAAAABAAAAPT////4/////P///wQABAAEAAAA\",\n",
      "  \"__jax_leaf_ids\": [\n",
      "    \"Array(int64[]) -> 0\",\n",
      "    \"Array(float64[2, 1024, 1024]) -> 1\",\n",
      "    \"Array(float64[3]) -> 2\",\n",
      "    \"Array(float64[4]) -> 3\",\n",
      "    \"Array(float64[5]) -> 4\"\n",
      "  ]\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "The leaf data is organized in a flat directory under `leaf_data`\n",
      "\u001b[01;34m/tmp/tmpd_q_p7_z\u001b[0m\n",
      "├── \u001b[01;34marray_store.tensorstore\u001b[0m\n",
      "│   ├── \u001b[01;34md\u001b[0m\n",
      "│   │   ├── \u001b[00m0f97594e20094eaac7ce29d7b5c0b315\u001b[0m\n",
      "│   │   ├── \u001b[00mbfe3326f332b44066f7c6d524af98a7c\u001b[0m\n",
      "│   │   └── \u001b[00mea4c038215fcfe6a5f22594f8c5366c9\u001b[0m\n",
      "│   └── \u001b[00mmanifest.ocdbt\u001b[0m\n",
      "└── \u001b[00mpytreedef.json\u001b[0m\n",
      "\n",
      "3 directories, 5 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The `pytreedef.json` is a human-readable pytree stored format\")\n",
    "print((Path(tempdir) / \"pytreedef.json\").read_text())\n",
    "print(\"-\" * 80)\n",
    "print(\"The leaf data is organized in a flat directory under `leaf_data`\")\n",
    "print(check_output([\"tree\", tempdir]).decode()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "PyTree Structure:\n",
      "[ShapeDtypeStruct(shape=(), dtype=int64),\n",
      " {'world': [ShapeDtypeStruct(shape=(2, 1024, 1024), dtype=float64),\n",
      "            (ShapeDtypeStruct(shape=(3,), dtype=float64),\n",
      "             ShapeDtypeStruct(shape=(4,), dtype=float64))]},\n",
      " ShapeDtypeStruct(shape=(5,), dtype=float64)]\n",
      "--------------------------------------------------------------------------------\n",
      "Partial read of data:\n",
      "[Array(1, dtype=int64),\n",
      " {'world': [Array([[[1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.]],\n",
      "\n",
      "       [[1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.],\n",
      "        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float64),\n",
      "            (Array([0., 0., 0.], dtype=float64),\n",
      "             Array([1., 1., 1., 1.], dtype=float64))]},\n",
      " Array([1., 1., 1., 1., 1.], dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "# read only the data structure\n",
    "print(\"-\" * 80)\n",
    "print(\"PyTree Structure:\")\n",
    "pytree_structure = tree.load_pytreedef(tempdir)\n",
    "pprint(pytree_structure)\n",
    "\n",
    "# read only integers back\n",
    "print(\"-\" * 80)\n",
    "print(\"Partial read of data:\")\n",
    "#pytree_structure = jax.tree.map(lambda x: x if x.startswith(\"int\") else None, \n",
    "#                                pytree_structure)\n",
    "new_data = tree.load(tempdir, pytree=pytree_structure)\n",
    "pprint(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytree_mask = jax.tree.map(condition_fn, tree.load_pytreedef(tempdir))\n",
    "new_data = tree.load(tempdir, pytree=pytree_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom node registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "arr = jnp.ones(10)\n",
    "fut = nonblocking_save(arr, tempdir)\n",
    "while not fut.done():\n",
    "  time.sleep(1e-3)\n",
    "fut = nonblocking_load(tempdir)\n",
    "print(fut.pytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "@functools.partial(register_pytree_node_serialization,\n",
    "                   serialized_name=\"CustomNode\",\n",
    "                   serialize_auxdata=json.dumps,\n",
    "                   deserialize_auxdata=json.loads)\n",
    "@functools.partial(jax.tree_util.register_dataclass, data_fields=[\"a\", \"b\"], \n",
    "                   meta_fields=[\"op\"])\n",
    "@dataclass \n",
    "class CustomNode:\n",
    "  a: Any\n",
    "  b: Any\n",
    "  op: str\n",
    "\n",
    "data = [\"hello\", {\"world\": [\"!\", (1, b\"data\")]}, None, (CustomNode(1, 2, \"hi\"))]\n",
    "tree.save(data, tempdir)\n",
    "out = tree.load(tempdir)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(register_pytree_node_serialization,\n",
    "                   serialized_name=\"CustomLeaf\",\n",
    "                   serialize_auxdata=lambda p: json.dumps(p.a),\n",
    "                   deserialize_auxdata=lambda x: CustomLeaf(json.loads(x)))\n",
    "@jax.tree_util.register_static\n",
    "@dataclass\n",
    "class CustomLeaf:\n",
    "  a: int = 2\n",
    "  \n",
    "@functools.partial(register_pytree_node_serialization,\n",
    "                   serialized_name=\"CustomNode\",\n",
    "                   serialize_auxdata=json.dumps,\n",
    "                   deserialize_auxdata=json.loads)\n",
    "@functools.partial(jax.tree_util.register_dataclass, data_fields=[\"a\", \"b\"], \n",
    "                   meta_fields=[\"op\"])\n",
    "@dataclass \n",
    "class CustomNode:\n",
    "  a: Any\n",
    "  b: Any\n",
    "  op: str\n",
    "\n",
    "def serialize_D(aux_data):\n",
    "  return json.dumps(aux_data)\n",
    "\n",
    "def deserialize_D(aux_data):\n",
    "  return json.loads(aux_data)\n",
    "\n",
    "data = [\"hello\", {\"world\": [\"!\", (1, 2)]}, None, (CustomLeaf(), CustomNode(1, 2, \"hi\"))]\n",
    "\n",
    "jax.tree.flatten(data)\n",
    "\n",
    "save(data, \"/tmp/hello\")\n",
    "out = load(\"/tmp/hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pybind_mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     (a := AutonomousDrivingMap(\u001b[32m0\u001b[39m)).lines = json.loads(data)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m AutonomousDrivingMap = \u001b[43mpybind_mod\u001b[49m.cpp_class\n\u001b[32m     17\u001b[39m register_pytree_leaf_serialization(\n\u001b[32m     18\u001b[39m   AutonomousDrivingMap, serialized_name=\u001b[33m\"\u001b[39m\u001b[33mAutonomousDrivingMap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m   serialize_leaf=AutonomousDrivingMap.serialize,\n\u001b[32m     20\u001b[39m   deserialize_leaf=AutonomousDrivingMap.deserialize)\n\u001b[32m     22\u001b[39m data = [\u001b[33m\"\u001b[39m\u001b[33mhello\u001b[39m\u001b[33m\"\u001b[39m, {\u001b[33m\"\u001b[39m\u001b[33mworld\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m!\u001b[39m\u001b[33m\"\u001b[39m, (\u001b[32m1\u001b[39m, \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m)]}, \u001b[38;5;28;01mNone\u001b[39;00m, (AutonomousDrivingMap(\u001b[32m5\u001b[39m))]\n",
      "\u001b[31mNameError\u001b[39m: name 'pybind_mod' is not defined"
     ]
    }
   ],
   "source": [
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "class AutonomousDrivingMap:\n",
    "  def __init__(self, chunks: int):\n",
    "    self.lines = [[\"blob\" for _ in range(j)] for j in range(chunks)]\n",
    "\n",
    "  @staticmethod\n",
    "  def serialize(self):\n",
    "    return json.dumps(self.lines)\n",
    "\n",
    "  @staticmethod\n",
    "  def deserialize(data):\n",
    "    (a := AutonomousDrivingMap(0)).lines = json.loads(data)\n",
    "    return a\n",
    "\n",
    "AutonomousDrivingMap = pybind_mod.cpp_class\n",
    "\n",
    "register_pytree_leaf_serialization(\n",
    "  AutonomousDrivingMap, serialized_name=\"AutonomousDrivingMap\",\n",
    "  serialize_leaf=AutonomousDrivingMap.serialize,\n",
    "  deserialize_leaf=AutonomousDrivingMap.deserialize)\n",
    "\n",
    "data = [\"hello\", {\"world\": [\"!\", (1, b\"data\")]}, None, (AutonomousDrivingMap(5))]\n",
    "tree.save(data, tempdir)\n",
    "print(tree.load(tempdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fallback serialization `pickle` and `json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly refusing to serialize custom objects\n"
     ]
    }
   ],
   "source": [
    "@functools.partial(jax.tree_util.register_dataclass, data_fields=[\"a\", \"c\"], \n",
    "                   meta_fields=[\"op\"])\n",
    "@dataclass\n",
    "class UnregisteredCustomNode:\n",
    "  op: str\n",
    "  a: Any\n",
    "  c: int\n",
    "  \n",
    "tmpdir = tempfile.TemporaryDirectory().name\n",
    "try:\n",
    "  save({\"dataclass\": UnregisteredCustomNode(\n",
    "    \"tanh\", random.normal(random.key(0), (7,)), 5), \"a\": 1}, tmpdir)\n",
    "except ValueError:\n",
    "  print(\"Correctly refusing to serialize custom objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental writing is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m tempdir = tempfile.TemporaryDirectory().name\n\u001b[32m      2\u001b[39m incremental_tree = [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincremental_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m incremental_tree[\u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m\n\u001b[32m      5\u001b[39m save(incremental_tree, tempdir, partial_write=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/jax/jax/experimental/array_serialization/pytree_serialization.py:312\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(data, directory, overwrite, ts_specs)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Saves the given data structure to the provided directory path.\u001b[39;00m\n\u001b[32m    289\u001b[39m \n\u001b[32m    290\u001b[39m \u001b[33;03mThis function provides functionality to serialize and save a data structure\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m \u001b[33;03m  save(data, directory)\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _THREADING_SAVE_LOCK:\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_specs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/jax/jax/experimental/array_serialization/pytree_serialization.py:354\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(data, directory, overwrite, ts_specs)\u001b[39m\n\u001b[32m    350\u001b[39m futures.append(executor.submit(_write_arrays, arrs_and_paths, full_ts_specs,\n\u001b[32m    351\u001b[39m                                distinct_locations))\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# wait for all futures to complete\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m _ = [\u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m futures]\n\u001b[32m    355\u001b[39m _sync_on_key(sync_key, \u001b[33m\"\u001b[39m\u001b[33marray_serialization\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arrs_and_paths) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/jax/jax/experimental/array_serialization/pytree_serialization.py:284\u001b[39m, in \u001b[36m_write_arrays\u001b[39m\u001b[34m(arrs_and_paths, full_ts_specs, distinct_locations)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_serialize_arrays\u001b[39m():\n\u001b[32m    279\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*[serialize_array(\n\u001b[32m    280\u001b[39m     arr, path, extra_ts_spec, distinct_locations)\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ((arr, path), extra_ts_spec)\n\u001b[32m    282\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arrs_and_paths, full_ts_specs)])\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_serialize_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/asyncio/runners.py:195\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/asyncio/runners.py:118\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, coro, context)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._interrupt_count = \u001b[32m0\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._interrupt_count > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/asyncio/base_events.py:691\u001b[39m, in \u001b[36mBaseEventLoop.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future.done():\n\u001b[32m    689\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/jax/jax/experimental/array_serialization/pytree_serialization.py:279\u001b[39m, in \u001b[36m_write_arrays.<locals>._serialize_arrays\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_serialize_arrays\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*[serialize_array(\n\u001b[32m    280\u001b[39m     arr, path, extra_ts_spec, distinct_locations)\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ((arr, path), extra_ts_spec)\n\u001b[32m    282\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arrs_and_paths, full_ts_specs)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/jax/jax/experimental/array_serialization/pytree_serialization.py:211\u001b[39m, in \u001b[36mserialize_array\u001b[39m\u001b[34m(arr, path, extra_config, distinct_locations)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mserialize_array\u001b[39m(arr, path, extra_config, distinct_locations: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    210\u001b[39m                           ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m   arr = jax.numpy.asarray(arr, dtype=\u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m)\n\u001b[32m    212\u001b[39m   extra_ts_spec = extra_config\n\u001b[32m    213\u001b[39m   process_num = (jax.process_index() \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    214\u001b[39m       jax.process_count() > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m distinct_locations) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "incremental_tree = [None, None, None]\n",
    "save(incremental_tree, tempdir)\n",
    "incremental_tree[0] = 1\n",
    "save(incremental_tree, tempdir, partial_write=True)\n",
    "ret = load(tempdir)\n",
    "print(ret)\n",
    "assert ret[0] == 1 and ret[1] is None and ret[2] is None\n",
    "incremental_tree[0] = None\n",
    "incremental_tree[1] = 4\n",
    "save(incremental_tree, tempdir, partial_write=True)\n",
    "ret = load(tempdir)\n",
    "print(ret)\n",
    "assert ret[0] == 1 and ret[1] == 4 and ret[2] is None\n",
    "incremental_tree[0], incremental_tree[2] = None, jnp.ones(4)\n",
    "save(incremental_tree, tempdir, partial_write=True)\n",
    "ret = load(tempdir)\n",
    "print(ret)\n",
    "#assert (ret[0] == 1 and ret[1] is None and (np.testing.assert_allclose(ret[2], jnp.ones(4)) is None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "tree.save([None, None, None], tempdir)\n",
    "print(tree.load(tempdir))\n",
    "tree.save([1, None, None], tempdir, partial_write=True)\n",
    "print(tree.load(tempdir))\n",
    "tree.save([None, 4, None], tempdir, partial_write=True)\n",
    "print(tree.load(tempdir))\n",
    "tree.save([None, None, jnp.ones(10)], tempdir, partial_write=True)\n",
    "print(tree.load(tempdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful! PyTree utils do not preserve key order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"c\": 1, \"a\": 2}\n",
    "d2 = jax.tree.unflatten(jax.tree.structure(d), jax.tree.flatten(d)[0])\n",
    "print(d)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `OrderedDict` is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict as odict\n",
    "d = odict({\"c\": 1, \"a\": 2})\n",
    "d2 = jax.tree.unflatten(jax.tree.structure(d), jax.tree.flatten(d)[0])\n",
    "print(d)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = tempfile.TemporaryDirectory().name\n",
    "fut = nonblocking_save(odict({\"c\": jnp.ones(100), \"a\": 2, \"none\": None}), tempdir)\n",
    "print(fut.pytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytree_def = load_pytreedef(tempdir)\n",
    "arr_tree = jax.tree.map(lambda x: x if x.startswith(\"Array\") else None, pytree_def)\n",
    "other_tree = jax.tree.map(lambda x: x if not x.startswith(\"Array\") else None, pytree_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load(tempdir, pytree=arr_tree))\n",
    "print(\"---\")\n",
    "print(load(tempdir, pytree=other_tree))\n",
    "print(\"---\")\n",
    "tree_together = jax.tree.map(lambda x, y: x if x is not None else y, load(tempdir, pytree=arr_tree), load(tempdir, pytree=other_tree), is_leaf=lambda x: x is None)\n",
    "print(tree_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = nonblocking_load(tempdir)\n",
    "while not ret.done():\n",
    "  pass\n",
    "ret = ret.result()\n",
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended safe-modules\n",
    "\n",
    "We probably want to be able to support non-JAX, but very standard collections\n",
    "like e.g., flax's `FrozenDict` (and I can't think of anything else).\n",
    "\n",
    "To do this programmatically, we can add **string** entries to \n",
    "`new_api._EXTENDED_NODE_TYPES_MAP` which we then use `importlib` on on the fly.\n",
    "\n",
    "The alternative is to allow this importlib on-the-fly import for all modules\n",
    "that are:\n",
    "1. not a member of `__main__` module \n",
    "2. do not contain any non-JSON serializable `node_data()`\n",
    "\n",
    "But this would mean calling `importlib.import_module` on a data string, so it's\n",
    "pretty unsafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "  save(collections.OrderedDict(a=1, b=jnp.ones(10)), tmpdir)\n",
    "  restored_tree = load(tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrozenDict(dict(a=1))\n",
    "\n",
    "try:\n",
    "  from flax.core.frozen_dict import FrozenDict\n",
    "  # FrozenDict is added to the list at the moment\n",
    "  with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    save(FrozenDict(a=1, b=jnp.ones(10)), tmpdir)\n",
    "    restored_tree = load(tmpdir)\n",
    "except ImportError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FrozenDict(dict(a=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. Must the resulting checkpoint be a directory? Can it not be a file?\n",
    "\n",
    "> The underlying checkpoint is a directory, tensorstore doesn't really support\n",
    "> writing single-file checkpoints that are well read-optimized.\n",
    "\n",
    "> It's possible to zip the result, piece-by-piece without wasting disk space,\n",
    "> which is probably a direction to explore. NOTE: tensorstore seems to support\n",
    "> **reading** from Python zipfile handles directly.\n",
    "\n",
    "2. How fast is saving the checkpoint given I/O can be slow?\n",
    "\n",
    "> Thanks to the underlying async usage, it should be pretty fast.\n",
    "\n",
    "3. Is RAM usage controlled?\n",
    "\n",
    "> Not at the moment, but it's possible to improve this. We can use tensorstore\n",
    "> to limit array writing memory usage and we can rewrite non-array writing to be\n",
    "> non-buffered through a bytes or text object (they are buffered to more cleanly\n",
    "> support file://, gcs://, s3:// alternatives).\n",
    "\n",
    "4. Why is the `pytreedef.json` weird like that?\n",
    "\n",
    "> The \"cleanest\" way to save a pytree structure is to just use a JSON\n",
    "> representation with leafs replaced with their data reference id. However,\n",
    "> JSON doesn't distinguish between tuple, list and so it doesn't really preserve\n",
    "> the actual pytree, even if it's limited to only in-built types. Also, when the\n",
    "> pytree contains custom nodes, we need a custom tree representation anyway.\n",
    "\n",
    "5. Isn't overwriting a **directory** checkpoint extremely dangerous if the \n",
    "\"checkpoint\" path turns out to be e.g. \"/usr/local\"?\n",
    "\n",
    "> Yes, but we first check for files and directories we didn't create and refuse\n",
    "> to overwrite if there are any.\n",
    "\n",
    "6. Why doesn't Python LSP not work with synchronous versions: `save`, `load`?\n",
    "\n",
    "I don't know, I need to fix it.\n",
    "\n",
    "7. Restored pytrees have dictionary node keys in a different order. Why?\n",
    "\n",
    "> This is pytree behavior, dictionaries order is not preserved.\n",
    "> [https://github.com/google/jax/issues/4085](https://github.com/google/jax/issues/4085)\n",
    "\n",
    "8. Which host (process_id) writes the save directory and what part of it?\n",
    "\n",
    "> Currently if remote path is detected, only `jax.process_idx() == 0` writes \n",
    "> non-arrays. All processes write arrays as that is what tensorstore expects.\n",
    "\n",
    "9. TODO\n",
    "\n",
    "> - passing sharding not tested"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
